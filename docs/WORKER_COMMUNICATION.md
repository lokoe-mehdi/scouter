# Architecture de Communication : Workers, Jobs & Logs

Ce document explique en d√©tail comment le Frontend (JS) et le Backend (Workers) communiquent.
Il n'y a **pas de connexion directe** (pas de WebSocket, pas de lien direct). Tout passe par la **Base de Donn√©es (PostgreSQL)** qui agit comme une bo√Æte aux lettres centrale.

---

## üó∫Ô∏è Vue d'ensemble (La "Big Picture")

L'architecture fonctionne sur le principe du **"Fire and Forget"** pour le front, et du **"Worker Polling"** pour le back.

1.  **Le Chef (Frontend)** : Envoie un ordre "D√©marre le crawl !" et re√ßoit un num√©ro de ticket (`job_id`).
2.  **La Bo√Æte aux Lettres (Database)** : Stocke l'ordre dans la table `jobs`.
3.  **L'Ouvrier (Worker)** : V√©rifie la bo√Æte aux lettres en permanence. D√®s qu'il voit un ordre, il le prend, le verrouille, et travaille.
4.  **Le Streaming** : L'ouvrier √©crit ses notes (`logs`) dans la base de donn√©es au fur et √† mesure. Le chef relit ces notes toutes les secondes.

---

## üîß Les Composants & Fichiers Cl√©s

Voici le r√¥le pr√©cis de chaque fichier dans cette danse.

### 1. Le Frontend (Command Center)
*   **Fichier** : `web/assets/crawl-panel.js`
*   **R√¥le** : Interface utilisateur.
*   **Action** :
    *   Au d√©marrage : Appelle `api/start-crawl.php`.
    *   Pendant le crawl : Appelle `api/get-job-logs.php` et `api/get-job-status.php` en boucle (toutes les ~1-2 secondes). C'est ce qu'on appelle du **Polling**.
    *   Ce n'est **PAS** du vrai streaming (comme Netflix), c'est du rafra√Æchissement rapide.

### 2. L'API (Le Guichetier)
*   **Fichiers** :
    *   `web/api/start-crawl.php` : Cr√©e une ligne dans la table `jobs` avec status `pending`.
    *   `web/api/get-running-crawls.php` : Regarde quels jobs sont actifs.
    *   `web/api/get-job-logs.php` : R√©cup√®re les lignes de la table `job_logs` pour un ID donn√©.
*   **R√¥le** : Faire l'interm√©diaire entre le JS et la Base de Donn√©es.

### 3. Le Gestionnaire (Le Cerveau)
*   **Fichier** : `app/JobManager.php`
*   **R√¥le** : Classe PHP centrale qui manipule SQL.
*   **M√©thodes Cl√©s** :
    *   `createJob()` : Ins√®re le job.
    *   `addLog()` : Ins√®re un log dans `job_logs`.
    *   `updateJobStatus()` : Change l'√©tat (pending -> running -> completed).

### 4. Le Worker (L'Ouvrier)
*   **Fichier** : `app/bin/worker.php`
*   **R√¥le** : Script PHP qui tourne **en infini** (via Docker Supervisor).
*   **Boucle (La "Zumba")** :
    1.  `SELECT * FROM jobs WHERE status = 'queued' FOR UPDATE SKIP LOCKED` : Cherche un job libre et pose un verrou dessus (pour √©viter que 2 workers prennent le m√™me).
    2.  `proc_open('php scouter.php crawl ...')` : Lance le VRAI script de crawl dans un sous-processus.
    3.  Capture la sortie (stdout) et l'√©crit dans un fichier `.log` physique.
    4.  Utilise `JobManager->addLog()` pour √©crire les logs structur√©s dans la DB.

---

## üîÑ Flux D√©taill√© : "De Start √† Logs"

Voici exactement ce qui se passe quand tu cliques sur "Start".

### √âtape 1 : Cr√©ation du Job
1.  **JS** : Envoie POST vers `/api/start-crawl.php`.
2.  **PHP** : `JobManager` ins√®re une ligne dans la table `jobs`.
    *   `status`: `pending`
    *   `project_dir`: `google.com`
3.  **PHP** : Rend l'ID `123` au JS.
4.  **JS** : Affiche le panneau et commence √† poller l'ID `123`.

### √âtape 2 : Prise en charge par le Worker
1.  **Worker.php** (qui boucle sans arr√™t) voit le job `123` en `queued` (ou `pending`).
2.  Il passe le status √† `running`.
3.  Il lance la commande syst√®me de crawl.

### √âtape 3 : La r√©cup√©ration des Logs (Le "Streaming")
C'est l√† que la magie (ou l'arnaque) op√®re.

1.  **C√¥t√© Worker** : Pendant que le crawl tourne, le code PHP du crawl appelle `$jobManager->addLog(123, "Page trouv√©e: /contact", "info")`.
    *   Cela ins√®re une ligne dans la table `job_logs`.
2.  **C√¥t√© Frontend** : Le JS a un `setInterval`.
    *   Il appelle `/api/get-job-logs.php?job_id=123`.
    *   L'API fait un `SELECT * FROM job_logs WHERE job_id = 123`.
    *   Le JS re√ßoit le JSON et l'ajoute dans la div noire du terminal.

### √âtape 4 : Fin du Job
1.  Le processus de crawl se termine (exit code 0).
2.  **Worker.php** d√©tecte la fin du processus.
3.  Il met √† jour la table `jobs` : `status = 'completed'`.
4.  Il met √† jour la table `crawls` (l'ancienne table) pour que le reste du site soit au courant.
5.  Le **JS** voit le status `completed` lors de son prochain poll et arr√™te de demander des logs.

---

## üö® Points Importants (Pourquoi c'est "Carr√©")

1.  **Ind√©pendance** : Si tu fermes ton navigateur, le Worker continue. Le job est en base de donn√©es.
2.  **Scalabilit√©** : Tu peux lancer 50 containers `worker`. Gr√¢ce au `FOR UPDATE SKIP LOCKED` (PostgreSQL), ils ne se marcheront jamais dessus.
3.  **Logs Persistants** : Les logs ne sont pas juste en m√©moire vive. Ils sont dans la table `job_logs`. Si tu recharges la page, l'historique revient.
4.  **Double Logging** :
    *   **DB (`job_logs`)** : Logs "propres" pour l'affichage UI (ex: "URL crawl√©", "Erreur 404").
    *   **Fichier (`logs/projet.log`)** : Sortie brute du terminal (utile pour d√©bugger si le worker crash violemment).

## üõ† R√©sum√© des Tables SQL

*   **`jobs`** : La file d'attente. Contient l'√©tat (`pending`, `running`), le PID, et les dates.
*   **`job_logs`** : Le journal de bord. Li√© √† `jobs` par `job_id`. Contient le message et le type (`info`, `error`).
*   **`crawls`** : L'ancienne table principale. Elle est maintenue √† jour "en miroir" par `JobManager` pour la compatibilit√© avec le reste du site.
